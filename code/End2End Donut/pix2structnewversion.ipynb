{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U datasets transformers pyarrow polyleven -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-30T15:11:10.766017Z","iopub.execute_input":"2023-05-30T15:11:10.766389Z","iopub.status.idle":"2023-05-30T15:11:22.891298Z","shell.execute_reply.started":"2023-05-30T15:11:10.766356Z","shell.execute_reply":"2023-05-30T15:11:22.890010Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport re\nimport json\nfrom collections import Counter\nfrom itertools import chain\nfrom pathlib import Path\nfrom typing import List, Dict, Union, Tuple, Any\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom PIL import Image\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import (\n    AutoProcessor,\n    Pix2StructConfig,\n    Pix2StructForConditionalGeneration,\n    get_linear_schedule_with_warmup,\n)\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom datasets import Image as ds_img\nfrom polyleven import levenshtein # a faster version of levenshtein\nimport cv2\nfrom torch.cuda.amp import GradScaler, autocast","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:15:32.446451Z","iopub.execute_input":"2023-05-30T15:15:32.447830Z","iopub.status.idle":"2023-05-30T15:15:32.464358Z","shell.execute_reply.started":"2023-05-30T15:15:32.447778Z","shell.execute_reply":"2023-05-30T15:15:32.463128Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_dir = Path(\"/kaggle/input/benetech-making-graphs-accessible/train\")\nimages_path = data_dir / \"images\"\ntrain_json_files = list((data_dir / \"annotations\").glob(\"*.json\"))\n\nclass CFG:\n\n    # General\n    debug = False\n    num_proc = 2\n    num_workers = 2\n    gpus = 1\n    max_patch = 1024\n    # Data\n    max_length = 512\n    image_height = 256\n    image_width = 256\n\n    # Training\n    epochs = 2\n    val_check_interval = 1.0  # how many times we want to validate during an epoch\n    check_val_every_n_epoch = 1\n    gradient_clip_val = 1.0\n    lr = 3e-5\n    lr_scheduler_type = \"cosine\"\n    num_warmup_steps = 100\n    seed = 42\n    warmup_steps = 300  \n    output_path = \"/content/output\"\n    log_steps = 200\n    batch_size = 2\n    use_wandb = False","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:15:44.715546Z","iopub.execute_input":"2023-05-30T15:15:44.715905Z","iopub.status.idle":"2023-05-30T15:15:44.931453Z","shell.execute_reply.started":"2023-05-30T15:15:44.715878Z","shell.execute_reply":"2023-05-30T15:15:44.930456Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"PROMPT_TOKEN = \"<|BOS|>\"\nX_START = \"<x_start>\"\nX_END = \"<x_end>\"\nY_START = \"<y_start>\"\nY_END = \"<y_end>\"\n# PROMPT_END_TOKEN = \"</|PROMPT|>\"\n\nSEPARATOR_TOKENS = [\n    PROMPT_TOKEN,\n    X_START,\n    X_END,\n    Y_START,\n    Y_END,\n#     PROMPT_END_TOKEN\n]\n\nLINE_TOKEN =  \"<line>\" \nVERTICAL_BAR_TOKEN = \"<vertical_bar>\"\n# HORIZONTAL_BAR_TOKEN = \"<horizontal_bar>\"\n# SCATTER_TOKEN = \"<scatter>\"\nDOT_TOKEN = \"<dot>\"\n\nCHART_TYPE_TOKENS = [\n    LINE_TOKEN,\n    VERTICAL_BAR_TOKEN,\n    # HORIZONTAL_BAR_TOKEN,\n    # SCATTER_TOKEN,\n    DOT_TOKEN\n]\n\nnew_tokens = SEPARATOR_TOKENS + CHART_TYPE_TOKENS","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:15:46.253180Z","iopub.execute_input":"2023-05-30T15:15:46.253583Z","iopub.status.idle":"2023-05-30T15:15:46.260005Z","shell.execute_reply.started":"2023-05-30T15:15:46.253551Z","shell.execute_reply":"2023-05-30T15:15:46.259063Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"new_tokens","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:15:48.814230Z","iopub.execute_input":"2023-05-30T15:15:48.815054Z","iopub.status.idle":"2023-05-30T15:15:48.829295Z","shell.execute_reply.started":"2023-05-30T15:15:48.815010Z","shell.execute_reply":"2023-05-30T15:15:48.828128Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['<|BOS|>',\n '<x_start>',\n '<x_end>',\n '<y_start>',\n '<y_end>',\n '<line>',\n '<vertical_bar>',\n '<dot>']"},"metadata":{}}]},{"cell_type":"code","source":"def is_nan(value: Union[int, float, str]) -> bool:\n     return isinstance(value, float) and str(value) == \"nan\"\n\ndef round_float(value: Union[int, float, str]) -> Union[str, float]:\n    if isinstance(value, float):\n        value = str(value)\n\n        if \".\" in value:\n            integer, decimal = value.split(\".\")\n            if abs(float(integer)) > 1:\n                decimal = decimal[:1]\n            else:\n                decimal = decimal[:4]\n\n            value = integer + \".\" + decimal\n    return value\n\ndef get_gt_string_and_xy(filepath: Union[str, os.PathLike]) -> Dict[str, str]:\n    filepath = Path(filepath)\n\n    with open(filepath) as fp:\n        data = json.load(fp)\n\n    data_series = data[\"data-series\"]\n\n    all_x, all_y = [], []\n\n    for d in data_series:\n        x = d[\"x\"]\n        y = d[\"y\"]\n\n        x = round_float(x)\n        y = round_float(y)\n\n        # Ignore nan values\n        if is_nan(x) or is_nan(y):\n            continue\n\n        all_x.append(x)\n        all_y.append(y)\n        \n    \n    if data['chart-type'] in ['horizontal_bar','scatter']:\n       return None\n    \n    chart_type = f\"<{data['chart-type']}>\"\n    x_str = X_START + \";\".join(list(map(str, all_x))) + X_END\n    y_str = Y_START + \";\".join(list(map(str, all_y))) + Y_END\n    \n    gt_string = PROMPT_TOKEN + chart_type + x_str + y_str\n\n    return {\n        \"ground_truth\": gt_string,\n        \"x\": json.dumps(all_x),\n        \"y\": json.dumps(all_y),\n        \"chart-type\": data[\"chart-type\"],\n        \"id\": filepath.stem,\n        \"source\": data[\"source\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:15:50.678166Z","iopub.execute_input":"2023-05-30T15:15:50.678711Z","iopub.status.idle":"2023-05-30T15:15:50.701458Z","shell.execute_reply.started":"2023-05-30T15:15:50.678658Z","shell.execute_reply":"2023-05-30T15:15:50.700187Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"processor = AutoProcessor.from_pretrained('hoangphu7122002ai/pix2struct_v0',is_vqa=False)\nmodel = Pix2StructForConditionalGeneration.from_pretrained('hoangphu7122002ai/pix2struct_v0')\nprocessor.image_processor.size = {\n    \"height\": CFG.image_height,\n    \"width\": CFG.image_width,\n}\n","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:15:56.677365Z","iopub.execute_input":"2023-05-30T15:15:56.678078Z","iopub.status.idle":"2023-05-30T15:16:35.880436Z","shell.execute_reply.started":"2023-05-30T15:15:56.678043Z","shell.execute_reply":"2023-05-30T15:16:35.879361Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)rocessor_config.json:   0%|          | 0.00/303 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eb6337be5cd40cf9679fc320bec90e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/2.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"596ce72e8a144fefa8baa9fdfb5929e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/851k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f0e04d9803d4439b9e42c7af011529d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/3.27M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e27a82b0be449b88ab6de6c7f2784d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)in/added_tokens.json:   0%|          | 0.00/171 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"991c3748f2d045c7ab1a9ffd719efb89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d971e1863c4e4d8c9549a032cef11362"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/4.91k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92c84577a20244e48a662c0208d7831f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/1.13G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0786b7290cd4ca5b9d98bbd203f683b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/164 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f479f7c8f6c44a097a9e18f4f1096e2"}},"metadata":{}}]},{"cell_type":"code","source":"processor.tokenizer.add_tokens(new_tokens)\nmodel.resize_token_embeddings(len(processor.tokenizer))","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:16:46.803068Z","iopub.execute_input":"2023-05-30T15:16:46.803489Z","iopub.status.idle":"2023-05-30T15:16:46.813008Z","shell.execute_reply.started":"2023-05-30T15:16:46.803446Z","shell.execute_reply":"2023-05-30T15:16:46.811899Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Embedding(50352, 768)"},"metadata":{}}]},{"cell_type":"code","source":"model.config.text_config.is_decoder=True","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:16:49.432159Z","iopub.execute_input":"2023-05-30T15:16:49.432552Z","iopub.status.idle":"2023-05-30T15:16:49.437546Z","shell.execute_reply.started":"2023-05-30T15:16:49.432522Z","shell.execute_reply":"2023-05-30T15:16:49.436211Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nds = []\nfor f in tqdm(train_json_files):\n    res = get_gt_string_and_xy(f)\n    if res is None:\n       continue\n    row = {\n        **res,\n        \"image_path\": str(images_path / f\"{f.stem}.jpg\"),\n    }\n    ds.append(row)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:16:51.220291Z","iopub.execute_input":"2023-05-30T15:16:51.221291Z","iopub.status.idle":"2023-05-30T15:20:44.027718Z","shell.execute_reply.started":"2023-05-30T15:16:51.221254Z","shell.execute_reply":"2023-05-30T15:20:44.026697Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 60578/60578 [03:52<00:00, 260.22it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"ds[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:27:42.030589Z","iopub.execute_input":"2023-05-30T15:27:42.030980Z","iopub.status.idle":"2023-05-30T15:27:42.040892Z","shell.execute_reply.started":"2023-05-30T15:27:42.030951Z","shell.execute_reply":"2023-05-30T15:27:42.039978Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'ground_truth': '<|BOS|><line><x_start>10%;20%;30%;40%;50%;60%;70%<x_end><y_start>1.5481;11.5;14.0;12.2;7.9;1.7140;5.7<y_end>',\n 'x': '[\"10%\", \"20%\", \"30%\", \"40%\", \"50%\", \"60%\", \"70%\"]',\n 'y': '[\"1.5481\", \"11.5\", \"14.0\", \"12.2\", \"7.9\", \"1.7140\", \"5.7\"]',\n 'chart-type': 'line',\n 'id': 'cc68f19b708c',\n 'source': 'extracted',\n 'image_path': '/kaggle/input/benetech-making-graphs-accessible/train/images/cc68f19b708c.jpg'}"},"metadata":{}}]},{"cell_type":"code","source":"type(ds)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:27:43.251587Z","iopub.execute_input":"2023-05-30T15:27:43.251941Z","iopub.status.idle":"2023-05-30T15:27:43.257956Z","shell.execute_reply.started":"2023-05-30T15:27:43.251914Z","shell.execute_reply":"2023-05-30T15:27:43.256941Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"list"},"metadata":{}}]},{"cell_type":"code","source":"split = 0.90\ntrain_samples = int(len(ds) * split)\ntrain_ds = ds[:train_samples+1]\nvalid_ds = ds[train_samples:]","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:27:44.829731Z","iopub.execute_input":"2023-05-30T15:27:44.830092Z","iopub.status.idle":"2023-05-30T15:27:44.836566Z","shell.execute_reply.started":"2023-05-30T15:27:44.830063Z","shell.execute_reply":"2023-05-30T15:27:44.835380Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"type(train_ds)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:27:50.415628Z","iopub.execute_input":"2023-05-30T15:27:50.415979Z","iopub.status.idle":"2023-05-30T15:27:50.424479Z","shell.execute_reply.started":"2023-05-30T15:27:50.415952Z","shell.execute_reply":"2023-05-30T15:27:50.423494Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"list"},"metadata":{}}]},{"cell_type":"code","source":"def augments():\n    return A.Compose([\n        A.Resize(width=CFG.image_width, height=CFG.image_height),\n        A.Normalize(\n            mean=[0, 0, 0],\n            std=[1, 1, 1],\n            max_pixel_value=255,\n        ),\n        ToTensorV2(),\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:27:53.058027Z","iopub.execute_input":"2023-05-30T15:27:53.058395Z","iopub.status.idle":"2023-05-30T15:27:53.064158Z","shell.execute_reply.started":"2023-05-30T15:27:53.058365Z","shell.execute_reply":"2023-05-30T15:27:53.063208Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class BeneTechDataset(Dataset):\n    def __init__(self, dataset, processor, augments=None):\n        self.dataset = dataset\n        self.processor = processor\n        self.augments = augments\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        item = self.dataset[idx]\n        image = cv2.imread(item['image_path'])\n        if self.augments:\n            image = self.augments(image=image)['image']\n        encoding = self.processor(\n            images=image,\n            return_tensors=\"pt\", \n            add_special_tokens=True, \n            max_patches=CFG.max_patch\n        )\n        \n        encoding = {k:v.squeeze() for k,v in encoding.items()}\n        encoding[\"text\"] = item[\"ground_truth\"]\n        return encoding","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:27:54.368044Z","iopub.execute_input":"2023-05-30T15:27:54.368569Z","iopub.status.idle":"2023-05-30T15:27:54.378211Z","shell.execute_reply.started":"2023-05-30T15:27:54.368540Z","shell.execute_reply":"2023-05-30T15:27:54.377242Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def collator(batch):\n    new_batch = {\"flattened_patches\":[], \"attention_mask\":[]}\n    texts = [item[\"text\"] for item in batch]\n    text_inputs = processor(\n        text=texts, \n        padding=\"max_length\", \n        truncation=True, \n        return_tensors=\"pt\", \n        add_special_tokens=True, \n        max_length=CFG.max_length\n    )\n    new_batch[\"labels\"] = text_inputs.input_ids\n    for item in batch:\n        new_batch[\"flattened_patches\"].append(item[\"flattened_patches\"])\n        new_batch[\"attention_mask\"].append(item[\"attention_mask\"])\n    new_batch[\"flattened_patches\"] = torch.stack(new_batch[\"flattened_patches\"])\n    new_batch[\"attention_mask\"] = torch.stack(new_batch[\"attention_mask\"])\n\n    return new_batch","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:27:57.268246Z","iopub.execute_input":"2023-05-30T15:27:57.268975Z","iopub.status.idle":"2023-05-30T15:27:57.276754Z","shell.execute_reply.started":"2023-05-30T15:27:57.268942Z","shell.execute_reply":"2023-05-30T15:27:57.275638Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_dataset = BeneTechDataset(train_ds, processor, augments=augments())\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=CFG.batch_size, collate_fn=collator)\n\nvalid_dataset = BeneTechDataset(valid_ds, processor, augments=augments())\nvalid_dataloader = DataLoader(valid_dataset, shuffle=False, batch_size=CFG.batch_size, collate_fn=collator)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:27:59.454710Z","iopub.execute_input":"2023-05-30T15:27:59.455189Z","iopub.status.idle":"2023-05-30T15:27:59.467730Z","shell.execute_reply.started":"2023-05-30T15:27:59.455156Z","shell.execute_reply":"2023-05-30T15:27:59.466654Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:28:01.258272Z","iopub.execute_input":"2023-05-30T15:28:01.259218Z","iopub.status.idle":"2023-05-30T15:28:01.389802Z","shell.execute_reply.started":"2023-05-30T15:28:01.259164Z","shell.execute_reply":"2023-05-30T15:28:01.388836Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'flattened_patches': tensor([[ 1.0000,  1.0000,  0.2292,  ...,  0.2292,  0.2292,  0.2292],\n         [ 1.0000,  2.0000,  0.2292,  ...,  0.2292,  0.2292,  0.2292],\n         [ 1.0000,  3.0000,  0.2292,  ...,  0.1643,  0.1643,  0.1643],\n         ...,\n         [32.0000, 30.0000,  0.2292,  ...,  0.2292,  0.2292,  0.2292],\n         [32.0000, 31.0000, -1.0661,  ...,  0.2292,  0.2292,  0.2292],\n         [32.0000, 32.0000, -0.3547,  ...,  0.2292,  0.2292,  0.2292]]),\n 'attention_mask': tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n 'text': '<|BOS|><line><x_start>10%;20%;30%;40%;50%;60%;70%<x_end><y_start>1.5481;11.5;14.0;12.2;7.9;1.7140;5.7<y_end>'}"},"metadata":{}}]},{"cell_type":"code","source":"for batch in train_dataloader:\n    print(batch)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:28:04.143857Z","iopub.execute_input":"2023-05-30T15:28:04.144245Z","iopub.status.idle":"2023-05-30T15:28:04.215117Z","shell.execute_reply.started":"2023-05-30T15:28:04.144214Z","shell.execute_reply":"2023-05-30T15:28:04.214204Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"{'flattened_patches': tensor([[[ 1.0000,  1.0000,  0.1421,  ...,  0.1421,  0.1421,  0.1421],\n         [ 1.0000,  2.0000,  0.1421,  ...,  0.1421,  0.1421,  0.1421],\n         [ 1.0000,  3.0000,  0.1421,  ...,  0.1421,  0.1421,  0.1421],\n         ...,\n         [32.0000, 30.0000,  0.1421,  ...,  0.1421,  0.1421,  0.1421],\n         [32.0000, 31.0000,  0.1421,  ...,  0.1421,  0.1421,  0.1421],\n         [32.0000, 32.0000,  0.1421,  ...,  0.1421,  0.1421,  0.1421]],\n\n        [[ 1.0000,  1.0000, -1.0359,  ..., -0.9233, -0.9233, -0.9233],\n         [ 1.0000,  2.0000, -0.9796,  ..., -0.8880, -0.8880, -0.8880],\n         [ 1.0000,  3.0000, -0.9233,  ..., -0.8387, -0.8387, -0.8387],\n         ...,\n         [32.0000, 30.0000, -0.8387,  ..., -0.9233, -0.9233, -0.9233],\n         [32.0000, 31.0000, -0.8880,  ..., -0.9796, -0.9796, -0.9796],\n         [32.0000, 32.0000, -0.9514,  ..., -1.0078, -1.0078, -1.0078]]]), 'attention_mask': tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n        [1., 1., 1.,  ..., 1., 1., 1.]]), 'labels': tensor([[50344, 50349, 50345,  ...,     0,     0,     0],\n        [50344, 50350, 50345,  ...,     0,     0,     0]])}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Model**","metadata":{}},{"cell_type":"markdown","source":"**Training**","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, processor, train_loader, optimizer, scaler):\n    \"\"\"\n    Trains the model on all batches for one epoch with NVIDIA's AMP\n    \"\"\"\n    model.train()\n    avg_loss = 0\n    with autocast():\n        prog_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n        for idx, batch in prog_bar:\n            labels = batch.pop(\"labels\").to('cuda')\n            flattened_patches = batch.pop(\"flattened_patches\").to('cuda')\n            attention_mask = batch.pop(\"attention_mask\").to('cuda')\n\n            outputs = model(\n                flattened_patches=flattened_patches,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n\n            loss = outputs.loss\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad(set_to_none=True)\n            prog_bar.set_description(f\"loss: {loss.item():.4f}\")\n            wandb_log(train_step_loss=loss.item())\n            avg_loss += loss.item()\n            \n    avg_loss = avg_loss / len(train_loader)\n    print(f\"Average training loss: {avg_loss:.4f}\")\n    wandb_log(train_loss=avg_loss)\n    return avg_loss\n\n@torch.no_grad()\ndef valid_one_epoch(model, processor, valid_loader):\n    \"\"\"\n    Validates the model on all batches (in val set) for one epoch\n    \"\"\"\n    model.eval()\n    avg_loss = 0\n    prog_bar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n    for idx, batch in prog_bar:\n        labels = batch.pop(\"labels\").to('cuda')\n        flattened_patches = batch.pop(\"flattened_patches\").to('cuda')\n        attention_mask = batch.pop(\"attention_mask\").to('cuda')\n        \n        outputs = model(\n            flattened_patches=flattened_patches,\n            attention_mask=attention_mask,\n            labels=labels\n        )\n        \n        loss = outputs.loss\n        prog_bar.set_description(f\"loss: {loss.item():.4f}\")\n        wandb_log(val_step_loss=loss.item())\n        avg_loss += loss.item()\n        \n    avg_loss = avg_loss / len(valid_loader)\n    print(f\"Average validation loss: {avg_loss:.4f}\")\n    wandb_log(val_loss=avg_loss)\n    return avg_loss","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:28:06.433553Z","iopub.execute_input":"2023-05-30T15:28:06.434779Z","iopub.status.idle":"2023-05-30T15:28:06.450927Z","shell.execute_reply.started":"2023-05-30T15:28:06.434743Z","shell.execute_reply":"2023-05-30T15:28:06.449930Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def fit(model, processor, train_loader, valid_loader, optimizer, scaler):\n    \"\"\"\n    A nice function that binds it all together and reminds me of Keras days from 2018 :)\n    \"\"\"\n    best_val_loss = int(1e+5)\n    for epoch in range(CFG.epochs):\n        print(f\"{'='*20} Epoch: {epoch+1} / {CFG.epochs} {'='*20}\")\n        _ = train_one_epoch(model, processor, train_loader, optimizer, scaler)\n        val_avg_loss = valid_one_epoch(model, processor, valid_loader)\n        \n        if val_avg_loss < best_val_loss:\n            best_val_loss = val_avg_loss\n            print(f\"Saving best model so far with loss: {best_val_loss:.4f}\")\n            processor.push_to_hub(\"hoangphu7122002ai/pix2struct_v0\",\n                                    commit_message=f\"valid best lost\")\n            model.push_to_hub(\"hoangphu7122002ai/pix2struct_v0\",\n                                        commit_message=f\"valid best lost\")\n    print(f\"Best model with val_loss: {best_val_loss:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:28:09.014044Z","iopub.execute_input":"2023-05-30T15:28:09.014709Z","iopub.status.idle":"2023-05-30T15:28:09.021426Z","shell.execute_reply.started":"2023-05-30T15:28:09.014675Z","shell.execute_reply":"2023-05-30T15:28:09.020457Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\"","metadata":{"execution":{"iopub.status.busy":"2023-05-30T15:28:44.831686Z","iopub.execute_input":"2023-05-30T15:28:44.832143Z","iopub.status.idle":"2023-05-30T15:28:46.497659Z","shell.execute_reply.started":"2023-05-30T15:28:44.832105Z","shell.execute_reply":"2023-05-30T15:28:46.496293Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\n\nwandb.finish()\n\ndef wandb_log(**kwargs):\n    for k, v in kwargs.items():\n        wandb.log({k: v})\n\n# Start W&B logging\n# W&B Login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwb_key = user_secrets.get_secret(\"donut\")\n\nwandb.login(key=wb_key)\n\nrun = wandb.init(\n    project='pytorch',\n    group='multi_modal',\n    job_type='train',\n)\n\nmodel.to('cuda')\nwandb.watch(model)\noptimizer = torch.optim.Adam(params=model.parameters(), lr=CFG.lr)\nfit(\n        model=model,\n        processor=processor,\n        train_loader=train_dataloader,\n        valid_loader=valid_dataloader,\n        optimizer=optimizer,\n        scaler=GradScaler(),\n    )","metadata":{"execution":{"iopub.status.busy":"2023-05-30T17:01:48.404861Z","iopub.execute_input":"2023-05-30T17:01:48.405247Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n","output_type":"stream"}]},{"cell_type":"code","source":"processor.push_to_hub(\"hoangphu7122002ai/pix2struct_v0\",\n                        commit_message=f\"valid best lost\")\nmodel.push_to_hub(\"hoangphu7122002ai/pix2struct_v0\",\n                            commit_message=f\"valid best lost\")","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:29:48.608495Z","iopub.execute_input":"2023-05-30T11:29:48.608913Z","iopub.status.idle":"2023-05-30T11:30:35.182717Z","shell.execute_reply.started":"2023-05-30T11:29:48.608876Z","shell.execute_reply":"2023-05-30T11:30:35.181721Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"447f81cee402492c961a7cac23593bcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.13G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2de56a99105c4cd0b93674fdeb662ce2"}},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/hoangphu7122002ai/pix2struct_v0/commit/c039b1ca978884a0f703433998bfd0e2898e0e2c', commit_message='valid best lost', commit_description='', oid='c039b1ca978884a0f703433998bfd0e2898e0e2c', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}